{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from scipy.signal import correlate2d, convolve2d\n",
    "from layer import Layer\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_data(x, y, limit):\n",
    "    zero_index = np.where(y == 0)[0][:limit]\n",
    "    one_index = np.where(y == 1)[0][:limit]\n",
    "    all_indices = np.hstack((zero_index, one_index))\n",
    "    all_indices = np.random.permutation(all_indices)\n",
    "    x, y = x[all_indices], y[all_indices]\n",
    "    x = x.reshape(len(x), 1, 28, 28)\n",
    "    x = x.astype(\"float32\") / 255\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# load MNIST from server, limit to 100 images per class since we're not training on GPU\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, y_train = preprocess_data(x_train, y_train, 1000)\n",
    "x_test, y_test = preprocess_data(x_test, y_test, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1, 28, 28)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.reshape(-1,28*28)\n",
    "y_test=y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 784)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(-1,28*28)\n",
    "y_train=y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_true, y_pred):\n",
    "    return -y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy_derivative(y_true, y_pred):\n",
    "   return (y_pred - y_true) / (y_pred * (1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        # TODO: return output\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        # TODO: update parameters and return input gradient\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size, alpha):\n",
    "        self.weights = np.random.rand(input_size, output_size)-0.5\n",
    "        self.bias = np.random.rand(1,output_size)-0.5\n",
    "        self.alpha = alpha\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.matmul(input, self.weights) + self.bias\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        weights_gradient = self.input.T.dot(output_gradient) + self.alpha * self.weights\n",
    "        input_gradient = output_gradient.dot(self.weights.T)\n",
    "        \n",
    "      \n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        return input_gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class reLU(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.maximum(self.input, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return output_gradient * (self.input > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Sigmoid(Layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = 1 / (1 + np.exp(-self.input))\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        return output_gradient * self.output * (1 - self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "    def __init__(self, input_shape, kernel_size, depth):\n",
    "        input_depth, input_height, input_width = input_shape\n",
    "        self.depth = depth\n",
    "        self.input_shape = input_shape\n",
    "        self.input_depth = input_depth\n",
    "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
    "        self.kernels = np.random.randn(*self.kernels_shape)\n",
    "        self.biases = np.random.randn(*self.output_shape)\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        self.output = np.copy(self.biases)\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                self.output[i] += correlate2d(self.input[j], self.kernels[i, j], \"valid\")\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        kernels_gradient = np.zeros(self.kernels_shape)\n",
    "        input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "        for i in range(self.depth):\n",
    "            for j in range(self.input_depth):\n",
    "                kernels_gradient[i, j] = correlate2d(self.input[j], output_gradient[i], \"valid\")\n",
    "                input_gradient[j] += convolve2d(output_gradient[i], self.kernels[i, j], \"full\")\n",
    "\n",
    "        self.kernels -= learning_rate * kernels_gradient\n",
    "        self.biases -= learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, x_train, y_train, learning_rate, epochs, loss_function, loss_derivative):\n",
    "    for epoch in range(epochs):\n",
    "        error = 0\n",
    "        for x, y in zip(x_train, y_train):\n",
    "            # forward\n",
    "            output = x.reshape(1,-1)\n",
    "            for layer in network:\n",
    "                output = layer.forward(output)\n",
    "            error += binary_crossentropy(y, output)\n",
    "           \n",
    "           \n",
    "            # backward\n",
    "            output_gradient = binary_crossentropy_derivative(y, output)\n",
    "           \n",
    "            for layer in reversed(network):\n",
    "                output_gradient = layer.backward(output_gradient, learning_rate)\n",
    "               \n",
    "        print(f\"Epoch {epoch}, error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, x_dataset):\n",
    "    results=np.zeros(x_dataset.shape[0])\n",
    "    for index,x in enumerate(x_dataset):\n",
    "        output = x.reshape(1,-1)\n",
    "        for layer in network:\n",
    "            output = layer.forward(output)\n",
    "        results[index]=output\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "network=[\n",
    "    Convolutional((1, 28, 28), 3, 5),\n",
    "    Dense(28*28, 40,0.01),\n",
    "    reLU(),\n",
    "    Dense(40, 1,0.01),\n",
    "    Sigmoid()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, error: [[-10688.62416122]]\n",
      "Epoch 1, error: [[-2801.05462769]]\n",
      "Epoch 2, error: [[-2268.11180785]]\n",
      "Epoch 3, error: [[-2107.32383404]]\n",
      "Epoch 4, error: [[-2016.30990799]]\n",
      "Epoch 5, error: [[-1968.07766726]]\n",
      "Epoch 6, error: [[-1938.48682008]]\n",
      "Epoch 7, error: [[-1904.22446223]]\n",
      "Epoch 8, error: [[-1878.50473727]]\n",
      "Epoch 9, error: [[-1855.15801487]]\n",
      "Epoch 10, error: [[-1838.9511582]]\n",
      "Epoch 11, error: [[-1824.68444313]]\n",
      "Epoch 12, error: [[-1811.95402489]]\n",
      "Epoch 13, error: [[-1799.38090077]]\n",
      "Epoch 14, error: [[-1789.5923762]]\n",
      "Epoch 15, error: [[-1781.1138455]]\n",
      "Epoch 16, error: [[-1773.58185686]]\n",
      "Epoch 17, error: [[-1766.97275018]]\n",
      "Epoch 18, error: [[-1761.38415264]]\n",
      "Epoch 19, error: [[-1755.55908487]]\n",
      "Epoch 20, error: [[-1751.9153298]]\n",
      "Epoch 21, error: [[-1746.62631923]]\n",
      "Epoch 22, error: [[-1742.39622398]]\n",
      "Epoch 23, error: [[-1737.8444319]]\n",
      "Epoch 24, error: [[-1733.91352699]]\n",
      "Epoch 25, error: [[-1730.81795444]]\n",
      "Epoch 26, error: [[-1726.58851016]]\n",
      "Epoch 27, error: [[-1723.74061576]]\n",
      "Epoch 28, error: [[-1720.15222384]]\n",
      "Epoch 29, error: [[-1717.01332709]]\n",
      "Epoch 30, error: [[-1714.12729028]]\n",
      "Epoch 31, error: [[-1711.01756923]]\n",
      "Epoch 32, error: [[-1708.26140102]]\n",
      "Epoch 33, error: [[-1705.43923378]]\n",
      "Epoch 34, error: [[-1703.01125464]]\n",
      "Epoch 35, error: [[-1700.69754667]]\n",
      "Epoch 36, error: [[-1698.55092315]]\n",
      "Epoch 37, error: [[-1696.01069265]]\n",
      "Epoch 38, error: [[-1693.93521096]]\n",
      "Epoch 39, error: [[-1692.11119919]]\n",
      "Epoch 40, error: [[-1690.22720167]]\n",
      "Epoch 41, error: [[-1688.23187411]]\n",
      "Epoch 42, error: [[-1686.3734686]]\n",
      "Epoch 43, error: [[-1684.48303357]]\n",
      "Epoch 44, error: [[-1682.60886892]]\n",
      "Epoch 45, error: [[-1681.11321847]]\n",
      "Epoch 46, error: [[-1679.89259872]]\n",
      "Epoch 47, error: [[-1678.27162582]]\n",
      "Epoch 48, error: [[-1677.03242425]]\n",
      "Epoch 49, error: [[-1675.34885371]]\n",
      "Epoch 50, error: [[-1674.01179856]]\n",
      "Epoch 51, error: [[-1672.70487902]]\n",
      "Epoch 52, error: [[-1671.54932202]]\n",
      "Epoch 53, error: [[-1670.14732088]]\n",
      "Epoch 54, error: [[-1668.63145299]]\n",
      "Epoch 55, error: [[-1667.50496364]]\n",
      "Epoch 56, error: [[-1666.46183636]]\n",
      "Epoch 57, error: [[-1665.49267622]]\n",
      "Epoch 58, error: [[-1664.2910428]]\n",
      "Epoch 59, error: [[-1663.3413646]]\n",
      "Epoch 60, error: [[-1662.34354351]]\n",
      "Epoch 61, error: [[-1660.91704607]]\n",
      "Epoch 62, error: [[-1659.62763559]]\n",
      "Epoch 63, error: [[-1658.95378129]]\n",
      "Epoch 64, error: [[-1657.87422063]]\n",
      "Epoch 65, error: [[-1657.06174919]]\n",
      "Epoch 66, error: [[-1656.22993165]]\n",
      "Epoch 67, error: [[-1655.44916942]]\n",
      "Epoch 68, error: [[-1654.64946307]]\n",
      "Epoch 69, error: [[-1653.83022701]]\n",
      "Epoch 70, error: [[-1652.82642852]]\n",
      "Epoch 71, error: [[-1651.91742128]]\n",
      "Epoch 72, error: [[-1651.36533707]]\n",
      "Epoch 73, error: [[-1650.54745186]]\n",
      "Epoch 74, error: [[-1649.62377193]]\n",
      "Epoch 75, error: [[-1649.16723466]]\n",
      "Epoch 76, error: [[-1648.68090294]]\n",
      "Epoch 77, error: [[-1647.80971691]]\n",
      "Epoch 78, error: [[-1646.96831606]]\n",
      "Epoch 79, error: [[-1646.24900016]]\n",
      "Epoch 80, error: [[-1645.44056347]]\n",
      "Epoch 81, error: [[-1644.89124476]]\n",
      "Epoch 82, error: [[-1644.28519552]]\n",
      "Epoch 83, error: [[-1643.47106328]]\n",
      "Epoch 84, error: [[-1642.99606625]]\n",
      "Epoch 85, error: [[-1642.32517332]]\n",
      "Epoch 86, error: [[-1641.70521035]]\n",
      "Epoch 87, error: [[-1641.21966348]]\n",
      "Epoch 88, error: [[-1640.58315756]]\n",
      "Epoch 89, error: [[-1640.12040905]]\n",
      "Epoch 90, error: [[-1639.46563456]]\n",
      "Epoch 91, error: [[-1638.90619453]]\n",
      "Epoch 92, error: [[-1638.23813314]]\n",
      "Epoch 93, error: [[-1637.72722019]]\n",
      "Epoch 94, error: [[-1637.21739378]]\n",
      "Epoch 95, error: [[-1636.68676205]]\n",
      "Epoch 96, error: [[-1636.09378212]]\n",
      "Epoch 97, error: [[-1635.40944019]]\n",
      "Epoch 98, error: [[-1635.04453294]]\n",
      "Epoch 99, error: [[-1634.55675773]]\n"
     ]
    }
   ],
   "source": [
    "train(network, x_train, y_train, 0.01, 100, binary_crossentropy, binary_crossentropy_derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/nix-shell.leaYbt/ipykernel_17654/2398593087.py:7: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  results[index]=output\n"
     ]
    }
   ],
   "source": [
    "results=predict(network,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_binary = np.where(results > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_binary=results_binary.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998989898989899"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, results_binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
